input {
  file {
    path              => "<LOG_PATH>/postgresql-*.log"
    start_position    => "beginning"
    sincedb_path      => "<SINCEDB_PATH>"
    discover_interval => 1
    stat_interval     => 0.5
    close_older       => 300
    ignore_older      => 0

  }
}

filter {
  # Add server metadata - can be set via environment variables or defaults
  mutate {
    add_field => {
      "cluster_name" => "${CLUSTER_NAME:<CLUSTER_NAME>}"
      "server_name" => "${SERVER_NAME:<HOSTNAME>}"
      "server_ip" => "${SERVER_IP:<IP>}"
    }
  }

  # Auto-detect server_name (hostname) if not set
  if [server_name] == "" {
    ruby {
      code => "
        require 'socket'
        event.set('server_name', Socket.gethostname)
      "
    }
  }

  # Auto-detect server_ip if not set
  if [server_ip] == "" {
    ruby {
      code => "
        require 'socket'
        begin
          hostname = Socket.gethostname
          ip_address = Socket.ip_address_list.detect{|intf| intf.ipv4? && !intf.ipv4_loopback?}
          event.set('server_ip', ip_address ? ip_address.ip_address : '127.0.0.1')
        rescue
          event.set('server_ip', '127.0.0.1')
        end
      "
    }
  }

  # Drop ERROR and STATEMENT lines (noise)
  if [message] =~ /^\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\.\d+\s+\w+\s+\[\d+\]\s+user=.*\s+(ERROR|STATEMENT):/ {
    drop { }
  }

  # Parse main PostgreSQL log structure (UTC timezone format)
  grok {
    match => {
      "message" => [
      '^%{TIMESTAMP_ISO8601:log_time}\s+(?<tz>(?:[+-]\d{2}(?::?\d{2})?|UTC))\s+\[%{NUMBER:pid}\]\s+user=%{DATA:username},db=%{DATA:database_name}, client_ip=%{DATA:client_ip}\s+app=%{DATA:application_name}\s+LOG:\s+%{GREEDYDATA:pg_message}$'
      ]
    }
    tag_on_failure => ["_grokparsefailure"]
  }
  ##########################################################################
  # If Logstash and PostgreSQL are running on the same database instance,
  # uncomment the following block to avoid self-logging (loop prevention)
  ##########################################################################
  #if [message] =~ /user=<USERNAME>)/ {
  #  drop { }
  #}
  if [pg_message] =~ /application_name=/ {
    grok {
      match => { "pg_message" => 'application_name=%{GREEDYDATA:application_name}$' }
      overwrite => ["application_name"]
      }
    mutate {
      strip => ["application_name"]
      }
    }
  # Only process if main grok succeeded
  if "_grokparsefailure" not in [tags] {
    
    # Combine timestamp with timezone (UTC handling)
    if [tz] == "UTC" {
      mutate { add_field => { "log_time_full" => "%{log_time} +00:00" } }
    } else {
      mutate { add_field => { "log_time_full" => "%{log_time} %{tz}" } }
    }
    
    date {
      match => ["log_time_full", "YYYY-MM-dd HH:mm:ss.SSS Z", "YYYY-MM-dd HH:mm:ss.SSS"]
      target => "log_time"
      timezone => "UTC"
    }

    # Route 1: Connection/Disconnection logs
    if [pg_message] =~ /^connection received:|^connection authorized:|^disconnection:/ {
      
      if [pg_message] =~ /^connection received:/ {
        mutate { add_field => { "action" => "connection_received" } }
      } else if [pg_message] =~ /^connection authorized:/ {
        mutate { add_field => { "action" => "connection" } }
      } else if [pg_message] =~ /^disconnection:/ {
        mutate { add_field => { "action" => "disconnection" } }
      }
      
      # Clean up fields for connection logs
      mutate {
        strip => ["username", "database_name", "client_ip", "action", "cluster_name", "server_name", "server_ip"]
        remove_field => ["log_time_full", "tz", "pid", "pg_message", "@version", "host", "event", "log", "message"]
      }
      
      # Tag for routing to connection_logs table
      mutate { add_tag => ["connection_log"] }
    }
    
    # Route 2: Audit logs
    else if [pg_message] =~ /^AUDIT:/ {
      
      # Parse AUDIT details
      grok {
        match => {
          "pg_message" => "AUDIT:\s+SESSION,%{NUMBER:session_id},%{NUMBER:statement_id},%{WORD:audit_type},%{GREEDYDATA:statement_details}"
        }
      }
      
      # Parse statement_details: command,object_type,object_name,statement_text
      grok {
        match => {
          "statement_details" => "(?<command>[^,]*),(?<object_type>[^,]*),(?<object_name>[^,]*),%{GREEDYDATA:statement_text}"
        }
        overwrite => ["command", "object_type", "object_name", "statement_text"]
      }
      
      # Clean up statement_text
      mutate {
        gsub => [
          "statement_text", ",<not logged>", "",
          "statement_text", "^\"|\"$", ""
        ]
      }
      
      # Handle empty object_type and object_name
      if [object_type] == "," or [object_type] == "" {
        mutate { replace => { "object_type" => "" } }
      }
      if [object_name] == "," or [object_name] == "" {
        mutate { replace => { "object_name" => "" } }
      }
      
      # Clean up fields for audit logs (keep client_ip for audit_logs now)
      mutate {
        strip => ["username", "session_id", "statement_id", "audit_type", "statement_text", "command", "object_type", "object_name", "cluster_name", "server_name", "server_ip", "client_ip"]
        remove_field => ["statement_details", "tz", "pid", "pg_message", "log_time_full", "@version", "host", "event", "log", "message", "database_name"]
      }
      
      # Tag for routing to audit_logs table
      mutate { add_tag => ["audit_log"] }
    }
    
    # Drop all other logs
    else {
      drop { }
    }
  }
  # Drop logs that failed main grok parsing
  else {
    drop { }
  }
}

output {
  # Output for connection logs
  if "connection_log" in [tags] {
    jdbc {
      connection_string => "jdbc:postgresql://<SERVER_IP>:<PORT>/<DATABASE_NAME>"
      driver_class      => "org.postgresql.Driver"
      driver_jar_path   => "<JDBC_JAR_PATH>"
      username          => "<USERNAME>"
      password          => "<PASSWORD>"
      statement => [
        "INSERT INTO connection_logs (log_time, username, database_name, client_ip, action, cluster_name, server_name, server_ip, application_name)
        VALUES (?::timestamptz, ?, ?, ?, ?, ?, ?, ?, ?)",
        "log_time", "username", "database_name", "client_ip", "action",
        "cluster_name", "server_name", "server_ip", "application_name"
        ]

      flush_size    => 1
      max_pool_size => 5
    }
  }

  # Output for audit logs (now includes client_ip)
  if "audit_log" in [tags] {
    jdbc {
      connection_string => "jdbc:postgresql://<SERVER_IP>:<PORT>/<DATABASE_NAME>"
      driver_class      => "org.postgresql.Driver"
      driver_jar_path   => "<JDBC_JAR_PATH>"
      username          => "<USERNAME>"
      password          => "<PASSWORD>"
      statement => [
        "INSERT INTO audit_logs (log_time, username, session_id, statement_id, audit_type, statement_text, command, object_type, object_name, cluster_name, server_name, server_ip,      client_ip, application_name)
        VALUES (?::timestamptz, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
        "log_time", "username", "session_id", "statement_id", "audit_type", "statement_text",
        "command", "object_type", "object_name", "cluster_name", "server_name", "server_ip",
        "client_ip", "application_name"
        ]

      flush_size    => 1
      max_pool_size => 5
    }
  }

  # Optional: Debug output (uncomment for troubleshooting)
  # stdout { codec => rubydebug }
}
